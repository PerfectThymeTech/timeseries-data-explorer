{
	"name": "IptvRawToCurated",
	"properties": {
		"description": "Dataflow to copy IPTV data from Raw to Curated",
		"folder": {
			"name": "IPTV"
		},
		"type": "MappingDataFlow",
		"typeProperties": {
			"sources": [
				{
					"linkedService": {
						"referenceName": "AzureDataLakeStorage",
						"type": "LinkedServiceReference"
					},
					"name": "AzureDataLakeSource",
					"description": "Source dataset in Azure Data Lake"
				}
			],
			"sinks": [
				{
					"linkedService": {
						"referenceName": "AzureDataLakeStorage",
						"type": "LinkedServiceReference"
					},
					"name": "AzureDataLakeSink",
					"description": "Sink dataset in Azure Data Lake",
					"rejectedDataLinkedService": {
						"referenceName": "AzureDataLakeStorage",
						"type": "LinkedServiceReference"
					}
				}
			],
			"transformations": [
				{
					"name": "DistinctRows"
				},
				{
					"name": "RenameColumns",
					"description": "Rename Columns"
				},
				{
					"name": "FilterEmptyHappinessScore",
					"description": "Filter Empty Happiness Score Rows"
				},
				{
					"name": "AlterRow"
				},
				{
					"name": "AddColumns",
					"description": "Add static pipeline ID column."
				}
			],
			"scriptLines": [
				"parameters{",
				"     sourceFolderPath as string,",
				"     sourceFileName as string,",
				"     sourceFileSystem as string,",
				"     sinkFileSystem as string,",
				"     sinkFolderPath as string,",
				"     logsFileSystem as string,",
				"     logsFolderPath as string,",
				"     pipelineId as string",
				"}",
				"source(output(",
				"          country as string,",
				"          service as string,",
				"          topology_5 as string,",
				"          topology_4 as string,",
				"          topology_3 as string,",
				"          topology_2 as string,",
				"          title as string,",
				"          service_type as string,",
				"          stb_model as string,",
				"          stb_manufacturer as string,",
				"          stb_sw_version as string,",
				"          streaming_protocol as string,",
				"          cdn_hostname as string,",
				"          cdn_pop as string,",
				"          channel_name as string,",
				"          happiness_score as float,",
				"          user_id as string,",
				"          end_time as timestamp 'yyyy-MM-dd\\'T\\'HH:mm:ss\\'Z\\''",
				"     ),",
				"     useSchema: false,",
				"     allowSchemaDrift: true,",
				"     validateSchema: false,",
				"     ignoreNoFilesFound: false,",
				"     format: 'delimited',",
				"     fileSystem: ($sourceFileSystem),",
				"     folderPath: ($sourceFolderPath),",
				"     fileName: ($sourceFileName),",
				"     columnDelimiter: ',',",
				"     escapeChar: '\\\\',",
				"     quoteChar: '\\\"',",
				"     columnNamesAsHeader: true) ~> AzureDataLakeSource",
				"AzureDataLakeSource aggregate(groupBy(hash = sha2(256,columns())),",
				"     each(match(true()), $$ = first($$))) ~> DistinctRows",
				"DistinctRows select(mapColumn(",
				"          Country = country,",
				"          Service = service,",
				"          ServiceType = service_type,",
				"          Topology2 = topology_2,",
				"          Topology3 = topology_3,",
				"          Topology4 = topology_4,",
				"          Topology5 = topology_5,",
				"          Title = title,",
				"          StbModel = stb_model,",
				"          StbManufacturer = stb_manufacturer,",
				"          StbSwVersion = stb_sw_version,",
				"          StreamingProtocol = streaming_protocol,",
				"          CdnHostname = cdn_hostname,",
				"          CdnPop = cdn_pop,",
				"          ChannelName = channel_name,",
				"          HappinessScore = happiness_score,",
				"          UserId = user_id,",
				"          EndTime = end_time,",
				"          Hash = hash",
				"     ),",
				"     skipDuplicateMapInputs: true,",
				"     skipDuplicateMapOutputs: true) ~> RenameColumns",
				"AddColumns filter(!isNull(HappinessScore)) ~> FilterEmptyHappinessScore",
				"FilterEmptyHappinessScore alterRow(upsertIf(true())) ~> AlterRow",
				"RenameColumns derive(PipelineId = $pipelineId) ~> AddColumns",
				"AlterRow sink(allowSchemaDrift: true,",
				"     validateSchema: false,",
				"     format: 'delta',",
				"     fileSystem: ($sinkFileSystem),",
				"     folderPath: ($sinkFolderPath),",
				"     mergeSchema: true,",
				"     autoCompact: true,",
				"     optimizedWrite: true,",
				"     vacuum: 0,",
				"     deletable: false,",
				"     insertable: false,",
				"     updateable: false,",
				"     upsertable: true,",
				"     keys:['Hash'],",
				"     umask: 0022,",
				"     preCommands: [],",
				"     postCommands: [],",
				"     skipDuplicateMapInputs: true,",
				"     skipDuplicateMapOutputs: true,",
				"     outputAssertFailedRows: true,",
				"     assertFailure_fileSystem: ($logsFileSystem),",
				"     assertFailure_folderPath: ($logsFolderPath),",
				"     partitionBy('key',",
				"          0,",
				"          Country",
				"     )) ~> AzureDataLakeSink"
			]
		}
	}
}